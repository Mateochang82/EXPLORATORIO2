[["verifiquemos-si-nuestra-variable-objetivo-tiene-comportamiento-normal.html", "Capítulo 10 Verifiquemos si nuestra variable objetivo tiene comportamiento normal 10.1 Interpretacion", " Capítulo 10 Verifiquemos si nuestra variable objetivo tiene comportamiento normal datos %&gt;% dplyr::group_by(school) %&gt;% dplyr::summarise( n = dplyr::n(), est_ks = suppressWarnings(ks.test(scale(g3), &#39;pnorm&#39;)$statistic), p_ks = suppressWarnings(ks.test(scale(g3), &#39;pnorm&#39;)$p.value), est_sw = shapiro.test(g3)$statistic, p_sw = shapiro.test(g3)$p.value, est_lt = lillie.test(g3)$statistic, p_lt = lillie.test(g3)$p.value ) ## # A tibble: 2 × 8 ## school n est_ks p_ks est_sw p_sw est_lt p_lt ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 GP 349 0.134 0.00000716 0.927 5.11e-12 0.134 1.31e-16 ## 2 MS 46 0.145 0.290 0.932 9.78e- 3 0.145 1.69e- 2 10.1 Interpretacion En ambos grupos, los valores de p son menores a 0.05, excepto en la prueba KS del colegio MS, donde el valor es 0.29. Sin embargo, al considerar el resto de pruebas, se rechaza la hipótesis nula de normalidad en ambos casos. Por lo tanto, la distribución de G3 no sigue una distribución normal ni en el colegio GP ni en el MS. Esto implica que, para comparar el rendimiento entre colegios, deberán utilizarse pruebas no paramétricas "],["verificamos-igualdad-de-varianzas.html", "Capítulo 11 Verificamos igualdad de varianzas 11.1 Comparación de dos grupos independientes con estadística no paramétrica (G3 y colegio) 11.2 Interpretacion", " Capítulo 11 Verificamos igualdad de varianzas 11.1 Comparación de dos grupos independientes con estadística no paramétrica (G3 y colegio) # Igualdad de varianzas (Brown–Forsythe / Levene robusto) leveneTest(g3 ~ school, data = datos, center = median) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 0.8377 0.3606 ## 393 # Mann–Whitney (versión rstatix) rstatix::wilcox_test(data = datos, formula = g3 ~ school, paired = FALSE) ## # A tibble: 1 × 7 ## .y. group1 group2 n1 n2 statistic p ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 g3 GP MS 349 46 8956 0.2 # Tamaño de efecto r (con IC) rstatix::wilcox_effsize(data = datos, formula = g3 ~ school, paired = FALSE, ci = TRUE) ## # A tibble: 1 × 9 ## .y. group1 group2 effsize n1 n2 conf.low conf.high magnitude ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; ## 1 g3 GP MS 0.0645 349 46 0.0023 0.16 small 11.2 Interpretacion Primero con la prueba de (Levene/Brown) podemos ver que p&gt;0.05, no se rechaza la hipotesis nula de homogeneidad de varianza. Esto confirma que las varianzas de la nota final (G3) son estadísticamente iguales entre los colegios GP y MS, incluso utilizando un método robusto debido a que no hay normalidad Segundo, con la prueba no parametrica de medianas(Mann-Whitney U) dado que p &gt; 0.05, no existe diferencia significativa en las medianas de G3 entre los dos colegios. En otras palabras, el desempeño académico promedio es equivalente en ambos grupos, incluso al usar una prueba no paramétrica "],["comparación-de-dos-grupos-no-pareados-con-estadística-no-paramétricag3-y-higher.html", "Capítulo 12 Comparación de dos grupos no pareados con estadística no paramétrica(G3 y higher) 12.1 Interpretacion", " Capítulo 12 Comparación de dos grupos no pareados con estadística no paramétrica(G3 y higher) # Igualdad de varianzas (robusta) car::leveneTest(g3 ~ higher, data = datos, center = median) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 0.2862 0.593 ## 393 # Alternativa aún más robusta fligner.test(g3 ~ higher, data = datos) ## ## Fligner-Killeen test of homogeneity of variances ## ## data: g3 by higher ## Fligner-Killeen:med chi-squared = 0.27065, df = 1, p-value = 0.6029 # Comparación de medianas (Mann–Whitney U) rstatix::wilcox_test(data = datos, formula = g3 ~ higher, paired = FALSE) ## # A tibble: 1 × 7 ## .y. group1 group2 n1 n2 statistic p ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 g3 no yes 20 375 2054. 0.000623 # Tamaño de efecto r (con intervalo de confianza) rstatix::wilcox_effsize(data = datos, formula = g3 ~ higher, paired = FALSE, ci = TRUE) ## # A tibble: 1 × 9 ## .y. group1 group2 effsize n1 n2 conf.low conf.high magnitude ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; ## 1 g3 no yes 0.172 20 375 0.09 0.25 small 12.1 Interpretacion Las pruebas de Levene y Fligner (p &gt; 0.05) indican que las varianzas son homogéneas entre los grupos, es decir, la dispersión de las notas finales (G3) es similar tanto en quienes desean continuar estudios superiores como en quienes no. Sin embargo, el test de Mann–Whitney U muestra una diferencia estadísticamente significativa (p = 0.0006) entre los grupos. Los estudiantes que respondieron “yes” a la pregunta sobre continuar estudios superiores presentan notas finales más altas que los que respondieron “no”. "],["comparación-de-dos-grupos-no-pareados-con-estadística-no-paramétricag3-y-studytime.html", "Capítulo 13 Comparación de dos grupos no pareados con estadística no paramétrica(G3 y studytime) 13.1 Interpretacion", " Capítulo 13 Comparación de dos grupos no pareados con estadística no paramétrica(G3 y studytime) # Convertimos failures en factor datos &lt;- datos %&gt;% dplyr::mutate(failures = as.factor(failures)) # Igualdad de varianzas (robusta) car::leveneTest(g3 ~ failures, data = datos, center = median) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 3 0.786 0.5023 ## 391 # Alternativa aún más robusta (Fligner–Killeen) fligner.test(g3 ~ failures, data = datos) ## ## Fligner-Killeen test of homogeneity of variances ## ## data: g3 by failures ## Fligner-Killeen:med chi-squared = 1.5615, df = 3, p-value = 0.6681 # Comparación no paramétrica (Kruskal–Wallis) rstatix::kruskal_test(data = datos, formula = g3 ~ failures) ## # A tibble: 1 × 6 ## .y. n statistic df p method ## * &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 g3 395 53.1 3 1.73e-11 Kruskal-Wallis # Comparaciones post-hoc si Kruskal es significativo rstatix::dunn_test(data = datos, formula = g3 ~ failures, p.adjust.method = &quot;bonferroni&quot;) ## # A tibble: 6 × 9 ## .y. group1 group2 n1 n2 statistic p p.adj p.adj.signif ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 g3 0 1 312 50 -4.42 0.00000979 0.0000588 **** ## 2 g3 0 2 312 17 -4.27 0.0000199 0.000120 *** ## 3 g3 0 3 312 16 -4.79 0.00000165 0.00000987 **** ## 4 g3 1 2 50 17 -1.38 0.166 0.997 ns ## 5 g3 1 3 50 16 -1.93 0.0533 0.320 ns ## 6 g3 2 3 17 16 -0.477 0.633 1 ns 13.1 Interpretacion haber reprobado alguna asignatura se asocia con un menor rendimiento académico final, mientras que los estudiantes sin antecedentes de reprobación mantienen las notas más altas. "],["kruskalwallis.html", "Capítulo 14 Kruskal–Wallis 14.1 Interpretacion", " Capítulo 14 Kruskal–Wallis # Pruebas no paramétricas para variables con 3 grupos o mas kruskal.test(g3 ~ mjob, data = datos) ## ## Kruskal-Wallis rank sum test ## ## data: g3 by mjob ## Kruskal-Wallis chi-squared = 16.127, df = 4, p-value = 0.002853 kruskal.test(g3 ~ fjob, data = datos) ## ## Kruskal-Wallis rank sum test ## ## data: g3 by fjob ## Kruskal-Wallis chi-squared = 6.2764, df = 4, p-value = 0.1794 kruskal.test(g3 ~ reason, data = datos) ## ## Kruskal-Wallis rank sum test ## ## data: g3 by reason ## Kruskal-Wallis chi-squared = 4.8664, df = 3, p-value = 0.1818 kruskal.test(g3 ~ guardian, data = datos) ## ## Kruskal-Wallis rank sum test ## ## data: g3 by guardian ## Kruskal-Wallis chi-squared = 3.8131, df = 2, p-value = 0.1486 kruskal.test(g3 ~ goout, data = datos) ## ## Kruskal-Wallis rank sum test ## ## data: g3 by goout ## Kruskal-Wallis chi-squared = 14.697, df = 4, p-value = 0.005372 kruskal.test(g3 ~ health, data = datos) ## ## Kruskal-Wallis rank sum test ## ## data: g3 by health ## Kruskal-Wallis chi-squared = 6.8039, df = 4, p-value = 0.1466 14.1 Interpretacion Despues de haber usado Kruskal–Wallis vemos que no todas las categorias se relacionan igual con G3. Por ejemplo vemos que mjob (trabajo de la madre) y goout (salir con amigos) sí muestran diferencias reales en la nota: χ²(4)=16.13, p=0.0029 y χ²(4)=14.70, p=0.0054. En cambio, fjob, reason, guardian y health no dan evidencia suficiente. Debido a esto toca hacer post hoc para ver que pares difieren. "],["post-hoc.html", "Capítulo 15 Post Hoc 15.1 Interpretacion", " Capítulo 15 Post Hoc # Post-hoc tras Kruskal: comparaciones par a par pairwise.wilcox.test(datos$g3, datos$mjob, exact = FALSE, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: datos$g3 and datos$mjob ## ## at_home health other services ## health 0.012 - - - ## other 1.000 0.021 - - ## services 0.108 1.000 0.339 - ## teacher 0.482 1.000 1.000 1.000 ## ## P value adjustment method: bonferroni pairwise.wilcox.test(datos$g3, datos$goout, exact = FALSE, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: datos$g3 and datos$goout ## ## 1 2 3 4 ## 2 1.000 - - - ## 3 1.000 1.000 - - ## 4 1.000 0.035 0.188 - ## 5 1.000 0.037 0.132 1.000 ## ## P value adjustment method: bonferroni pairwise.wilcox.test(datos$g3, datos$fjob, exact = FALSE, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: datos$g3 and datos$fjob ## ## at_home health other services ## health 1.00 - - - ## other 1.00 1.00 - - ## services 1.00 1.00 1.00 - ## teacher 1.00 1.00 0.18 0.31 ## ## P value adjustment method: bonferroni pairwise.wilcox.test(datos$g3, datos$reason, exact = FALSE, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: datos$g3 and datos$reason ## ## course home other ## home 1.00 - - ## other 1.00 1.00 - ## reputation 0.24 1.00 1.00 ## ## P value adjustment method: bonferroni pairwise.wilcox.test(datos$g3, datos$guardian, exact = FALSE, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: datos$g3 and datos$guardian ## ## father mother ## mother 1.00 - ## other 0.14 0.23 ## ## P value adjustment method: bonferroni pairwise.wilcox.test(datos$g3, datos$health, exact = FALSE, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: datos$g3 and datos$health ## ## 1 2 3 4 ## 2 1.00 - - - ## 3 0.11 1.00 - - ## 4 0.42 1.00 1.00 - ## 5 0.50 1.00 1.00 1.00 ## ## P value adjustment method: bonferroni 15.1 Interpretacion mjob = Con base en el ajuste de Bonferroni, se encontraron diferencias significativas entre health vs at_home (p = 0.012) y health vs other (p = 0.021). No se detectaron diferencias en los demás pares (p ≥ 0.108). Esto sugiere que el grupo health se comporta distinto frente a at_home y other en términos de G3. goout = Con Bonferroni, hubo diferencias para 4 vs 2 (p = 0.035) y 5 vs 2 (p = 0.037). El resto de comparaciones no fue significativo (p ≥ 0.132). Esto indica que los niveles altos de salidas (4–5) difieren del nivel bajo (2) en G3. fjob ,reason,guardian,health =No se encontraron diferencias significativas entre pares . "],["diagrama-de-dispersion.html", "Capítulo 16 Diagrama de dispersion", " Capítulo 16 Diagrama de dispersion datos %&gt;% ggplot(aes(x = g2, y = g3)) + geom_point(color = &quot;blue&quot;, size = 3) + geom_smooth(method = &quot;loess&quot;, se = TRUE, color = &quot;red&quot;) + labs( title = &quot;Relación entre G3 y G2 (tendencia LOESS)&quot;, x = &quot;G2 (nota segundo periodo)&quot;, y = &quot;G3 (nota final)&quot; ) + theme_bw() ## `geom_smooth()` using formula = &#39;y ~ x&#39; Como anteriormente mencionamosno tienen comportamiento normal por lo que pasaremos a ver el coeficiente de correlacion cor.test(datos$g3,datos$g2, method = &#39;spearman&#39;, exact=FALSE) ## ## Spearman&#39;s rank correlation rho ## ## data: datos$g3 and datos$g2 ## S = 440391, p-value &lt; 2.2e-16 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.9571253 El análisis de correlación de Spearman entre G2 y G3 mostro un coeficiente p = 0.9571253 lo que indica una correlación positiva muy alta; es decir,entre mejor sea g2 mejor es g3. La prueba de significancia (S = 440391, p-valor &lt; 0,001) permitió rechazar la hipótesis nula de ausencia de correlación, confirmando que la relación observada es estadísticamente significativa. "],["conclusiones.html", "Capítulo 17 Conclusiones", " Capítulo 17 Conclusiones Este análisis exploratorio nos permitió entender a fondo cómo se comporta el rendimiento académico de los estudiantes y qué factores parecen influir más en sus resultados finales. En primer lugar, las notas finales (G3) se concentran principalmente entre 8 y 14 puntos, con un promedio alrededor de 10. No se observan valores extremos ni distribuciones raras, lo que sugiere que el rendimiento es bastante estable. La mayoría de los estudiantes vive en zonas urbanas, pertenece al colegio GP y proviene de familias numerosas, aunque con niveles educativos de los padres más bien moderados. Cuando se compararon las notas con otras variables numéricas, la relación fue débil en casi todos los casos: edad, salud, consumo de alcohol o tiempo libre apenas tienen impacto. Lo que sí destaca es la fuerte conexión entre las notas previas (G1 y G2) y la nota final (G3): los estudiantes que empezaron bien, terminaron bien. En otras palabras, el rendimiento tiende a mantenerse constante durante el año. Las pruebas estadísticas también mostraron que no hay diferencias significativas entre colegios. Ni las medias ni las medianas de las calificaciones difieren de forma importante, y los tamaños de efecto son muy pequeños. Lo mismo ocurre al comparar las notas de los dos cortes (G2 vs G3): los resultados se mantienen prácticamente iguales, sin mejoras ni retrocesos estadísticamente relevantes. En resumen, los estudiantes presentan un rendimiento académico estable y bastante homogéneo. Las diferencias entre colegios o cortes son mínimas, y las variables personales o familiares no parecen modificar demasiado los resultados. Las calificaciones anteriores siguen siendo el mejor indicador del desempeño final: quien empieza bien, probablemente termina igual de bien. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
